{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import gzip\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_zipped_pickle(filename):\n",
    "    with gzip.open(filename, 'rb') as f:\n",
    "        loaded_object = pickle.load(f)\n",
    "        return loaded_object\n",
    "\n",
    "def save_zipped_pickle(obj, filename):\n",
    "    with gzip.open(filename, 'wb') as f:\n",
    "        pickle.dump(obj, f, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization of images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "train_data = load_zipped_pickle(\"./data/train.pkl\")\n",
    "#test_real_data = load_zipped_pickle(\"./data/test.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the number of videos\n",
    "num_videos = len(train_data)\n",
    "\n",
    "# Calculate the percentage of videos that are amateur or expert\n",
    "num_amateur = sum(data['dataset'] == 'amateur' for data in train_data)\n",
    "num_expert = sum(data['dataset'] == 'expert' for data in train_data)\n",
    "percentage_amateur = (num_amateur / num_videos) * 100\n",
    "percentage_expert = (num_expert / num_videos) * 100\n",
    "\n",
    "# Display the statistics\n",
    "print(f\"Number of videos: {num_videos}\")\n",
    "print(f\"Percentage of videos that are amateur: {percentage_amateur:.3}%\")\n",
    "print(f\"Percentage of videos that are expert: {percentage_expert:.3}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Assuming train_data is a list containing your data\n",
    "# Extract two samples, one labeled by an expert and one by an amateur\n",
    "expert_video = next(item for item in train_data if item['dataset'] == 'expert')\n",
    "amateur_video = next(item for item in train_data if item['dataset'] == 'amateur')\n",
    "\n",
    "# Function to plot frames\n",
    "def plot_frames(video, title):\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    plt.suptitle(title)\n",
    "    \n",
    "    # Plot three labeled frames\n",
    "    for i, frame_idx in enumerate(video['frames'][:3]):\n",
    "        plt.subplot(1, 3, i + 1)\n",
    "        plt.imshow(video['video'][:, :, frame_idx], cmap='gray')  # Assuming grayscale video\n",
    "        plt.title(f'Frame {frame_idx}')\n",
    "        plt.axis('off')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "# Plot frames for expert video\n",
    "plot_frames(expert_video, 'Expert Labeled Video')\n",
    "\n",
    "# Plot frames for amateur video\n",
    "plot_frames(amateur_video, 'Amateur Labeled Video')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Assuming train_data is a list containing your data\n",
    "# Extract two samples, one labeled by an expert and one by an amateur\n",
    "expert_video = next(item for item in train_data if item['dataset'] == 'expert')\n",
    "amateur_video = next(item for item in train_data if item['dataset'] == 'amateur')\n",
    "\n",
    "# Function to plot frames with labels\n",
    "def plot_frames_with_labels(video, title_prefix):\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    \n",
    "    # Plot three labeled frames with labels displayed\n",
    "    for i, frame_idx in enumerate(video['frames'][:3]):\n",
    "        plt.subplot(1, 3, i + 1)\n",
    "        frame = video['video'][:, :, frame_idx]\n",
    "        label = video['label'][:, :, frame_idx]\n",
    "        \n",
    "        plt.imshow(frame, cmap='gray')  # Assuming grayscale video\n",
    "        plt.title(f'{title_prefix} - Frame {frame_idx}')\n",
    "        \n",
    "        # Display labels on the image\n",
    "        for h in range(label.shape[0]):\n",
    "            for w in range(label.shape[1]):\n",
    "                if label[h, w]:\n",
    "                    plt.text(w, h, 'Label', color='red', fontsize=8, ha='center', va='center')\n",
    "\n",
    "        plt.axis('off')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "# Plot frames for expert video with labels\n",
    "plot_frames_with_labels(expert_video, f'Expert Labeled Video')\n",
    "\n",
    "# Plot frames for amateur video with labels\n",
    "plot_frames_with_labels(amateur_video, f'Amateur Labeled Video')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Assuming train_data is a list containing your data\n",
    "# Extract one sample for demonstration\n",
    "sample_video = train_data[0]\n",
    "\n",
    "# Function to plot frames with labels and boxes\n",
    "def plot_frames_with_labels_and_boxes(video, title_prefix):\n",
    "    plt.figure(figsize=(18, 6))\n",
    "    \n",
    "    # Plot three labeled frames with labels and boxes displayed\n",
    "    for i, frame_idx in enumerate(video['frames'][:3]):\n",
    "        plt.subplot(2, 3, i + 1)\n",
    "        frame = video['video'][:, :, frame_idx]\n",
    "        label = video['label'][:, :, frame_idx]\n",
    "        box = video['box']\n",
    "        \n",
    "        plt.imshow(frame, cmap='gray')  # Assuming grayscale video\n",
    "        plt.title(f'{title_prefix} - Frame {frame_idx}')\n",
    "        \n",
    "        # Display labels on the image\n",
    "        for h in range(label.shape[0]):\n",
    "            for w in range(label.shape[1]):\n",
    "                if label[h, w]:\n",
    "                    plt.text(w, h, 'Label', color='red', fontsize=8, ha='center', va='center')\n",
    "        \n",
    "        # Plot the bounding box\n",
    "        plt.subplot(2, 3, i + 4)\n",
    "        plt.imshow(frame, cmap='gray')  # Assuming grayscale video\n",
    "        plt.title(f'{title_prefix} - Frame {frame_idx} with Box')\n",
    "        \n",
    "        # Display the bounding box\n",
    "        box_indices = np.where(box)\n",
    "        plt.plot([box_indices[1].min(), box_indices[1].max(), box_indices[1].max(), box_indices[1].min(), box_indices[1].min()],\n",
    "                 [box_indices[0].min(), box_indices[0].min(), box_indices[0].max(), box_indices[0].max(), box_indices[0].min()],\n",
    "                 color='blue', linewidth=2)\n",
    "        \n",
    "        plt.axis('off')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "# Plot frames for the sample video with labels and boxes\n",
    "plot_frames_with_labels_and_boxes(sample_video, f'Sample Video ({sample_video[\"name\"]})')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_zipped_pickle(\"./data/train.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from skimage import exposure\n",
    "from skimage import transform as tf\n",
    "\n",
    "\n",
    "\n",
    "def preprocess_data(data, new_height, new_width):\n",
    "\n",
    "    video = data['video']\n",
    "    box = data['box']\n",
    "    label = data['label']\n",
    "\n",
    "    # Determine the minimum dimension among height and width\n",
    "    min_dimension = min(video.shape[0], video.shape[1])\n",
    "\n",
    "    # Resize video and box maintaining the aspect ratio\n",
    "    aspect_ratio = video.shape[1] / video.shape[0]\n",
    "    resized_width = new_width if aspect_ratio >= 1 else int(min_dimension * aspect_ratio)\n",
    "    resized_height = new_height if aspect_ratio <= 1 else int(min_dimension / aspect_ratio)\n",
    "\n",
    "    print(\"Resized dimensions:\", (resized_width, resized_height))\n",
    "\n",
    "    resized_video = cv2.resize(video.transpose(2, 0, 1), (resized_width, resized_height), interpolation=cv2.INTER_LINEAR).transpose(1, 2, 0)\n",
    "    resized_box = cv2.resize(box.astype(np.uint8), (resized_width, resized_height), interpolation=cv2.INTER_NEAREST).astype(bool)\n",
    "\n",
    "    # Normalize video and standardize box\n",
    "    normalized_video = resized_video / 255.0  # Normalize to [0, 1]\n",
    "    standardized_box = (resized_box - np.mean(resized_box)) / np.std(resized_box)\n",
    "\n",
    "    # Histogram Equalization on video\n",
    "    equalized_video = np.zeros_like(resized_video)\n",
    "    for i in range(resized_video.shape[2]):\n",
    "        equalized_video[..., i] = exposure.equalize_hist(resized_video[..., i])\n",
    "\n",
    "    # Data augmentation\n",
    "    augmented_video, augmented_box, augmented_label = augment_data(normalized_video, standardized_box, label)\n",
    "\n",
    "    return augmented_video, augmented_box, augmented_label\n",
    "\n",
    "def augment_data(video, box, label):\n",
    "    # Define data augmentation parameters\n",
    "    rotation_angle = 30\n",
    "    scaling_range = (0.8, 1.2)\n",
    "    translation_range = (10, 10)\n",
    "    shearing_range = 0.2\n",
    "\n",
    "    # Randomly apply data augmentation\n",
    "    if np.random.rand() > 0.5:\n",
    "        # Rotation\n",
    "        angle = np.random.uniform(-rotation_angle, rotation_angle)\n",
    "        video = tf.rotate(video, angle, mode='reflect')\n",
    "        box = tf.rotate(box.astype(float), angle, mode='reflect')\n",
    "        label = tf.rotate(label.astype(float), angle, mode='reflect')\n",
    "\n",
    "    if np.random.rand() > 0.5:\n",
    "        # Scaling\n",
    "        scaling_factor = np.random.uniform(scaling_range[0], scaling_range[1])\n",
    "        video = tf.rescale(video, scale=(scaling_factor, scaling_factor, 1), mode='reflect')\n",
    "        box = tf.rescale(box.astype(float), scale=(scaling_factor, scaling_factor), mode='reflect')\n",
    "\n",
    "        # Rescale each channel separately for label\n",
    "        rescaled_label_channels = []\n",
    "        for i in range(label.shape[2]):\n",
    "            rescaled_label_channels.append(tf.rescale(label[..., i].astype(float), scale=(scaling_factor, scaling_factor), mode='reflect'))\n",
    "        label = np.stack(rescaled_label_channels, axis=-1)\n",
    "\n",
    "    if np.random.rand() > 0.5:\n",
    "        # Translation\n",
    "        translation = (np.random.uniform(-translation_range[0], translation_range[0]),\n",
    "                       np.random.uniform(-translation_range[1], translation_range[1]))\n",
    "        video = tf.warp(video, tf.AffineTransform(translation=translation), mode='reflect')\n",
    "        box = tf.warp(box.astype(float), tf.AffineTransform(translation=translation), mode='reflect')\n",
    "\n",
    "        # Translate each channel separately for label\n",
    "        translated_label_channels = []\n",
    "        for i in range(label.shape[2]):\n",
    "            translated_label_channels.append(tf.warp(label[..., i].astype(float), tf.AffineTransform(translation=translation), mode='reflect'))\n",
    "        label = np.stack(translated_label_channels, axis=-1)\n",
    "\n",
    "    if np.random.rand() > 0.5:\n",
    "        # Shearing\n",
    "        shearing_factor = np.random.uniform(-shearing_range, shearing_range)\n",
    "        video = tf.warp(video, tf.AffineTransform(shear=shearing_factor), mode='reflect')\n",
    "        box = tf.warp(box.astype(float), tf.AffineTransform(shear=shearing_factor), mode='reflect')\n",
    "\n",
    "        # Shear each channel separately for label\n",
    "        sheared_label_channels = []\n",
    "        for i in range(label.shape[2]):\n",
    "            sheared_label_channels.append(tf.warp(label[..., i].astype(float), tf.AffineTransform(shear=shearing_factor), mode='reflect'))\n",
    "        label = np.stack(sheared_label_channels, axis=-1)\n",
    "\n",
    "    return video, box, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resized dimensions: (500, 500)\n",
      "Resized dimensions: (500, 500)\n",
      "Resized dimensions: (500, 500)\n",
      "Resized dimensions: (500, 500)\n",
      "Resized dimensions: (500, 500)\n",
      "Resized dimensions: (500, 500)\n",
      "Resized dimensions: (500, 500)\n",
      "Resized dimensions: (500, 500)\n",
      "Resized dimensions: (500, 500)\n",
      "Resized dimensions: (500, 500)\n",
      "Resized dimensions: (500, 500)\n",
      "Resized dimensions: (500, 500)\n",
      "Resized dimensions: (500, 500)\n",
      "Resized dimensions: (500, 500)\n",
      "Resized dimensions: (500, 500)\n",
      "Resized dimensions: (500, 500)\n",
      "Resized dimensions: (500, 500)\n",
      "Resized dimensions: (500, 500)\n",
      "Resized dimensions: (500, 500)\n",
      "Resized dimensions: (500, 500)\n",
      "Resized dimensions: (500, 500)\n",
      "Resized dimensions: (500, 500)\n",
      "Resized dimensions: (500, 500)\n",
      "Resized dimensions: (500, 500)\n",
      "Resized dimensions: (500, 500)\n",
      "Resized dimensions: (500, 500)\n",
      "Resized dimensions: (500, 500)\n",
      "Resized dimensions: (500, 500)\n",
      "Resized dimensions: (500, 500)\n",
      "Resized dimensions: (500, 500)\n",
      "Resized dimensions: (500, 500)\n",
      "Resized dimensions: (500, 500)\n",
      "Resized dimensions: (500, 500)\n",
      "Resized dimensions: (500, 500)\n",
      "Resized dimensions: (500, 500)\n",
      "Resized dimensions: (500, 500)\n",
      "Resized dimensions: (500, 500)\n",
      "Resized dimensions: (500, 500)\n",
      "Resized dimensions: (500, 500)\n",
      "Resized dimensions: (500, 500)\n",
      "Resized dimensions: (500, 500)\n",
      "Resized dimensions: (500, 500)\n",
      "Resized dimensions: (500, 500)\n",
      "Resized dimensions: (500, 500)\n",
      "Resized dimensions: (500, 500)\n",
      "Resized dimensions: (500, 500)\n",
      "Resized dimensions: (500, 532)\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(4.8.1) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\resize.cpp:3699: error: (-215:Assertion failed) !dsize.empty() in function 'cv::hal::resize'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\alois\\Desktop\\Advanced ML\\Project 3\\data_overview.ipynb Cell 12\u001b[0m line \u001b[0;36m8\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/alois/Desktop/Advanced%20ML/Project%203/data_overview.ipynb#X14sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m preprocessed_labels \u001b[39m=\u001b[39m []\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/alois/Desktop/Advanced%20ML/Project%203/data_overview.ipynb#X14sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39mfor\u001b[39;00m sample \u001b[39min\u001b[39;00m data:\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/alois/Desktop/Advanced%20ML/Project%203/data_overview.ipynb#X14sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     preprocessed_video, preprocessed_box, preprocessed_label \u001b[39m=\u001b[39m preprocess_data(sample, new_height, new_width)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/alois/Desktop/Advanced%20ML/Project%203/data_overview.ipynb#X14sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     preprocessed_videos\u001b[39m.\u001b[39mappend(preprocessed_video)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/alois/Desktop/Advanced%20ML/Project%203/data_overview.ipynb#X14sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     preprocessed_boxes\u001b[39m.\u001b[39mappend(preprocessed_box)\n",
      "\u001b[1;32mc:\\Users\\alois\\Desktop\\Advanced ML\\Project 3\\data_overview.ipynb Cell 12\u001b[0m line \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/alois/Desktop/Advanced%20ML/Project%203/data_overview.ipynb#X14sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m \u001b[39m# Print the resized dimensions for debugging\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/alois/Desktop/Advanced%20ML/Project%203/data_overview.ipynb#X14sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mResized dimensions:\u001b[39m\u001b[39m\"\u001b[39m, (resized_width, resized_height))\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/alois/Desktop/Advanced%20ML/Project%203/data_overview.ipynb#X14sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m resized_video \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mresize(video\u001b[39m.\u001b[39mtranspose(\u001b[39m2\u001b[39m, \u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m), (resized_width, resized_height), interpolation\u001b[39m=\u001b[39mcv2\u001b[39m.\u001b[39mINTER_LINEAR)\u001b[39m.\u001b[39mtranspose(\u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m, \u001b[39m0\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/alois/Desktop/Advanced%20ML/Project%203/data_overview.ipynb#X14sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m resized_box \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mresize(box\u001b[39m.\u001b[39mastype(np\u001b[39m.\u001b[39muint8), (resized_width, resized_height), interpolation\u001b[39m=\u001b[39mcv2\u001b[39m.\u001b[39mINTER_NEAREST)\u001b[39m.\u001b[39mastype(\u001b[39mbool\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/alois/Desktop/Advanced%20ML/Project%203/data_overview.ipynb#X14sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m \u001b[39m# Normalize video and standardize box\u001b[39;00m\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.8.1) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\resize.cpp:3699: error: (-215:Assertion failed) !dsize.empty() in function 'cv::hal::resize'\n"
     ]
    }
   ],
   "source": [
    "new_height, new_width = 500, 500 \n",
    "\n",
    "preprocessed_videos = []\n",
    "preprocessed_boxes = []\n",
    "preprocessed_labels = []\n",
    "\n",
    "for sample in data:\n",
    "    preprocessed_video, preprocessed_box, preprocessed_label = preprocess_data(sample, new_height, new_width)\n",
    "    \n",
    "    preprocessed_videos.append(preprocessed_video)\n",
    "    preprocessed_boxes.append(preprocessed_box)\n",
    "    preprocessed_labels.append(preprocessed_label)\n",
    "\n",
    "# Convert lists to numpy arrays for further processing\n",
    "preprocessed_videos = np.array(preprocessed_videos)\n",
    "preprocessed_boxes = np.array(preprocessed_boxes)\n",
    "preprocessed_labels = np.array(preprocessed_labels)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'preprocessed_video' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\alois\\Desktop\\Advanced ML\\Project 3\\data_overview.ipynb Cell 13\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/alois/Desktop/Advanced%20ML/Project%203/data_overview.ipynb#X32sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mlen\u001b[39m(preprocessed_video))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'preprocessed_video' is not defined"
     ]
    }
   ],
   "source": [
    "print(len(preprocessed_video))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## U-net single channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_unet(input_shape):\n",
    "    inputs = keras.Input(shape=input_shape)\n",
    "    # ... (U-Net architecture with appropriate layers)\n",
    "    # Example U-Net architecture with contracting and expansive paths\n",
    "    x = layers.Conv2D(32, 3, activation=\"relu\", padding=\"same\")(inputs)\n",
    "    x = layers.MaxPooling2D(3, strides=2, padding=\"same\")(x)\n",
    "    x = layers.Conv2D(64, 3, activation=\"relu\", padding=\"same\")(x)\n",
    "    x = layers.MaxPooling2D(3, strides=2, padding=\"same\")(x)\n",
    "    x = layers.Conv2D(128, 3, activation=\"relu\", padding=\"same\")(x)\n",
    "    x = layers.MaxPooling2D(3, strides=2, padding=\"same\")(x)\n",
    "    x = layers.Conv2D(256, 3, activation=\"relu\", padding=\"same\")(x)\n",
    "\n",
    "    # Upsampling and concatenation\n",
    "    x = layers.UpSampling2D(size=(2, 2))(x)\n",
    "    x = layers.concatenate([x, layers.Conv2DTranspose(128, 3, activation=\"relu\", padding=\"same\")(layers.MaxPooling2D(pool_size=(2, 2))(x))])\n",
    "    x = layers.Conv2D(128, 3, activation=\"relu\", padding=\"same\")(x)\n",
    "\n",
    "    x = layers.UpSampling2D(size=(2, 2))(x)\n",
    "    x = layers.concatenate([x, layers.Conv2DTranspose(64, 3, activation=\"relu\", padding=\"same\")(layers.MaxPooling2D(pool_size=(2, 2))(x))])\n",
    "    x = layers.Conv2D(64, 3, activation=\"relu\", padding=\"same\")(x)\n",
    "\n",
    "    x = layers.UpSampling2D(size=(2, 2))(x)\n",
    "    x = layers.concatenate([x, layers.Conv2DTranspose(32, 3, activation=\"relu\", padding=\"same\")(layers.MaxPooling2D(pool_size=(2, 2))(x))])\n",
    "    x = layers.Conv2D(32, 3, activation=\"relu\", padding=\"same\")(x)\n",
    "\n",
    "    outputs = layers.Conv2D(1, 1, activation=\"sigmoid\")(x)\n",
    "\n",
    "    return keras.Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'frames' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\alois\\Desktop\\Advanced ML\\Project 3\\data_overview.ipynb Cell 16\u001b[0m line \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/alois/Desktop/Advanced%20ML/Project%203/data_overview.ipynb#X15sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Build and train the model\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/alois/Desktop/Advanced%20ML/Project%203/data_overview.ipynb#X15sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m model \u001b[39m=\u001b[39m build_unet(input_shape\u001b[39m=\u001b[39mframes\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m:])\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/alois/Desktop/Advanced%20ML/Project%203/data_overview.ipynb#X15sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m model\u001b[39m.\u001b[39mcompile(loss\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mbinary_crossentropy\u001b[39m\u001b[39m\"\u001b[39m, optimizer\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39madam\u001b[39m\u001b[39m\"\u001b[39m, metrics\u001b[39m=\u001b[39m[\u001b[39m\"\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/alois/Desktop/Advanced%20ML/Project%203/data_overview.ipynb#X15sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m model\u001b[39m.\u001b[39mfit(train_dataset, epochs\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m, validation_data\u001b[39m=\u001b[39mval_dataset)  \u001b[39m# Adjust epochs based on performance\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'frames' is not defined"
     ]
    }
   ],
   "source": [
    "# Build and train the model\n",
    "model = build_unet(input_shape=frames.shape[1:])\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "model.fit(train_dataset, epochs=10, validation_data=val_dataset)  # Adjust epochs based on performance\n",
    "\n",
    "# Save the trained model\n",
    "model.save(\"mitral_valve_segmentation.h5\")\n",
    "\n",
    "# Evaluate the model on the validation set\n",
    "val_loss, val_acc = model.evaluate(val_dataset)\n",
    "print(f\"Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard_index(y_true, y_pred):\n",
    "    intersection = tf.reduce_sum(y_true * y_pred)\n",
    "    union = tf.reduce_sum(y_true) + tf.reduce_sum(y_pred) - intersection\n",
    "    return (intersection + 1e-7) / (union + 1e-7)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\alois\\Desktop\\Advanced ML\\Project 3\\data_overview.ipynb Cell 18\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/alois/Desktop/Advanced%20ML/Project%203/data_overview.ipynb#X20sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m predictions \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mpredict(test_dataset)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/alois/Desktop/Advanced%20ML/Project%203/data_overview.ipynb#X20sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39m# Calculate Jaccard Index for each frame\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/alois/Desktop/Advanced%20ML/Project%203/data_overview.ipynb#X20sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m jaccard_indices \u001b[39m=\u001b[39m []\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(test_dataset)\n",
    "\n",
    "# Calculate Jaccard Index for each frame\n",
    "jaccard_indices = []\n",
    "for i, (frames, label, prediction) in enumerate(zip(test_dataset)):\n",
    "    for frame, pred, gt in zip(frames, prediction, label):\n",
    "        jaccard_index_value = jaccard_index(gt, pred)\n",
    "        jaccard_indices.append(jaccard_index_value)\n",
    "\n",
    "# Compute median Jaccard Index\n",
    "median_jaccard_index = np.median(jaccard_indices)\n",
    "\n",
    "print(f\"Median Jaccard Index: {median_jaccard_index:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
